{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_Language_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shp7408/Natural_Language_processing/blob/main/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 자연어 처리(Natural Language Processing)\u001c\n",
        "- 자연어는 일상 생활에서 사용하는 언어\n",
        "- 자연어 처리는 자연어의 의미를 분석 처리하는 일\n",
        "- 텍스트 분류, 감성 분석, 문서 요약, 번역, 질의 응답, 음성 인식, 챗봇과 같은 응용\n",
        "\n",
        "# 텍스트 처리"
      ],
      "metadata": {
        "id": "yKNodnWccU55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = 'No pain no gain'\n",
        "'pain' in s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUYcYQ5XctXW",
        "outputId": "f659125e-22a9-4c72-9604-6fd474ba7e7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBZXiIiJc1q8",
        "outputId": "93901b37-fc8c-4094-93d7-b83eefdddd33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['No', 'pain', 'no', 'gain']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.split().index('gain')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYZhi0QDc90U",
        "outputId": "8a522a75-40c5-40ed-8b5e-aa088843177d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[-4:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UP_pDvxcdDoQ",
        "outputId": "595349b7-28e1-4b82-df6f-038cb6636827"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " s.split()[2][::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V8if-zPAdFeR",
        "outputId": "8c614fd5-2a7e-482e-ad0a-e1e110476a06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'on'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = '한글도 처리 가능'"
      ],
      "metadata": {
        "id": "zsBN38jAdecl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'처리' in s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYqRfNnhdlB0",
        "outputId": "7e4a10ce-4e52-45a8-d14c-d4f13a070b68"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CPQ_wVvdnMc",
        "outputId": "e1c7db2a-9519-42c0-82ed-8666e4d9c80d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['한글도', '처리', '가능']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.split()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zfGi-hemdpnn",
        "outputId": "be726959-35c3-4a22-c638-bbdbdf056e42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'한글도'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정규화(Normalization)"
      ],
      "metadata": {
        "id": "ScNga4ZjeMw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"I visited UK from US on 22-09-20\"\n",
        "print(s)"
      ],
      "metadata": {
        "id": "AJKUg1ljdvpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad486b7-1d1e-4609-b961-d5e623e6bac7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I visited UK from US on 22-09-20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_s = s.replace(\"UK\", \"United Kingdom\").replace(\"US\", \"United States\").replace(\"-20\", \"-2020\")\n",
        "print(new_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIwVWesNn476",
        "outputId": "870661c3-e9a7-4ab7-d742-90433bf70424"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I visited United Kingdom from United States on 22-09-2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정규표현식\n",
        "- 정규 표현식은 특정 문자들을 편리하게 지정하고 추가, 삭제 가능\n",
        "- 데이터 전처리에서 정규 표현식을 많이 사용\n",
        "- 파이썬에서는 정규 표현식을 지원하는 **re** 패키지 지원\n",
        "\n",
        "| 특수문자 | 설명 |\n",
        "| - | - |\n",
        "| `.` | 앞의 문자 1개를 표현 |\n",
        "| `?` | 문자 한개를 표현하나 존재할 수도, 존재하지 않을 수도 있음(0개 또는 1개) |\n",
        "| `*` | 앞의 문자가 0개 이상 |\n",
        "| `+` | 앞의 문자가 최소 1개 이상 |\n",
        "| `^` | 뒤의 문자로 문자열이 시작 |\n",
        "| `\\$` | 앞의 문자로 문자열이 끝남 |\n",
        "| `\\{n\\}` | `n`번만큼 반복 |\n",
        "| `\\{n1, n2\\}` | `n1` 이상, `n2` 이하만큼 반복, n2를 지정하지 않으면 `n1` 이상만 반복 |\n",
        "| `\\[ abc \\]` | 안에 문자들 중 한 개의 문자와 매치, a-z처럼 범위도 지정 가능 |\n",
        "| `\\[ ^a \\]` | 해당 문자를 제외하고 매치 |\n",
        "| `a\\|b` | `a` 또는 `b`를 나타냄 |\n",
        "\n",
        "- 정규 표현식에서 자주 사용하는 역슬래시(\\)를 이용한 문자 규칙\n",
        "\n",
        "| 문자 | 설명 |\n",
        "| - | - |\n",
        "| `\\\\` | 역슬래시 자체를 의미 |\n",
        "| `\\d` | 모든 숫자를 의미, [0-9]와 동일 |\n",
        "| `\\D` | 숫자를 제외한 모든 문자를 의미, [^0-9]와 동일 |\n",
        "| `\\s` | 공백을 의미, [ \\t\\n\\r\\f\\v]와 동일|\n",
        "| `\\S` | 공백을 제외한 모든 문자를 의미, [^ \\t\\n\\r\\f\\v]와 동일 |\n",
        "| `\\w` | 문자와 숫자를 의미, [a-zA-Z0-9]와 동일 |\n",
        "| `\\W` | 문자와 숫자를 제외한 다른 문자를 의미, [^a-zA-Z0-9]와 동일 |\n",
        "\n",
        "# match\n",
        "- 컴파일한 정규 표현식을 이용해 문자열이 정규 표현식과 맞는지 검사\n"
      ],
      "metadata": {
        "id": "1viHZZdSoly0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "WMNspZqJoKpV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check = 'ab.'\n",
        "\n",
        "print(re.match(check, 'abc'))\n",
        "print(re.match(check, 'c'))\n",
        "print(re.match(check, 'ab'))\n",
        "print(re.match(check, 'ab '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DaDIY8d12Vs",
        "outputId": "5a8ac03e-6fea-4497-9f82-3ecb63e2a4db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 3), match='abc'>\n",
            "None\n",
            "None\n",
            "<re.Match object; span=(0, 3), match='ab '>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check = 'ab.'에서 . 은 문자를 의미한다. 'ab'의 경우에는, b 뒤에 아무 문자열이 없어서, None을 리턴한다."
      ],
      "metadata": {
        "id": "7YlcmE5x13Im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# compile\n",
        "- compile을 사용하면, 여러 번 사용할 겅우, 일반 사용보다 더 빠른 속도를 보인다.\n",
        " - compile을 통해 정규 표현식을 사용할 경우, **re** 가 아닌 컴파일한 객체 이름을 통해 사용해야 한다."
      ],
      "metadata": {
        "id": "rAXVEWly2LZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "normal_s_time = time.time()\n",
        "r ='ab.'\n",
        "for i in range(1000):\n",
        "  re.match(check, 'abc')\n",
        "print('일반 사용 시, 소요 시간 : ', time.time() - normal_s_time)\n",
        "\n",
        "compile_s_time = time.time()\n",
        "r = re.compile('ab.')\n",
        "for i in range(1000):\n",
        "  r.match(check)\n",
        "print('컴파일 사용 시, 소요 시간 : ', time.time() - compile_s_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUJugg7d2gtT",
        "outputId": "832501e6-ac5a-453f-b939-2d5514f65532"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "일반 사용 시, 소요 시간 :  0.010440587997436523\n",
            "컴파일 사용 시, 소요 시간 :  0.0007832050323486328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# search\n",
        "  - match와 다르게, search는 문자열의 전체를 검사"
      ],
      "metadata": {
        "id": "Uh8y7jkT33QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check = 'ab?'\n",
        "print(re.search('a', check))\n",
        "print(re.match('kkkab',check))\n",
        "print(re.search('kkkab', check))\n",
        "print(re.match('ab', check))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJPLgztr4JD3",
        "outputId": "8704b0a6-41f4-4356-802e-4cf7fe87ad7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 1), match='a'>\n",
            "None\n",
            "None\n",
            "<re.Match object; span=(0, 2), match='ab'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# split\n",
        "- 정규 표현식에 해당하는 문자열을 기준으로 문자열을 나눔"
      ],
      "metadata": {
        "id": "0AePSiPc5cu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = re.compile(' ')\n",
        "print(r.split('abc abbv abcbab'))\n",
        "\n",
        "r = re.compile('c')\n",
        "print(r.split('abc abbc abcbab'))\n",
        "\n",
        "r = re.compile('[1-9]')\n",
        "print(r.split('s1abc 2v3s 4sss 5a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5J5m8ou4Ql-",
        "outputId": "5e28b56f-4bc9-461f-bc93-317f7407dcdc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abc', 'abbv', 'abcbab']\n",
            "['ab', ' abb', ' ab', 'bab']\n",
            "['s', 'abc ', 'v', 's ', 'sss ', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sub\n",
        "- 정규 표현식과 일치하는 부분을 다른 문자열로 교체"
      ],
      "metadata": {
        "id": "Pq2tMXbN6i4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(re.sub('[a-z]', 'abcdefg', '1'))\n",
        "print(re.sub('[^a-z]', 'abv defg', '1'))\n",
        "print(re.sub('[^a-z]', 'abvdefg2', '1'))\n",
        "print(re.sub('[^a-z]', '333', '1'))\n",
        "print(re.sub('[^a-z]', '!@!@', '1'))\n",
        "print(re.sub('[^a-z]', 'AA', '1'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oavp-xFw6pXr",
        "outputId": "b8061509-9cd1-4896-e50a-c8da6885c5db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "abv defg\n",
            "abvdefg2\n",
            "333\n",
            "!@!@\n",
            "AA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# findall\n",
        "- 컴파일한 정규 표현식을 이용해 정규 표현식과 맞는 모든 문자(열)을 리스트로 반환"
      ],
      "metadata": {
        "id": "49SArwTB7MPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(re.findall('[\\d]', '1ab 2cd 3ef 4g'))\n",
        "print(re.findall('[\\W]', '!abcd@@#'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0kFDUPY66Gr",
        "outputId": "d2dedb3d-11b1-4561-d971-bffab436217a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '2', '3', '4']\n",
            "['!', '@', '@', '#']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# finditer\n",
        "- 컴파일한 정규 표현식을 이용해 정규 표현식과 맞는 모든 문자(열)을 iteratror 객체로 반환\n",
        "- iterator 객체를 이용하면, 생성된 객체를 하나씩 자동으로 가져올 수 있어 처리가 간편함"
      ],
      "metadata": {
        "id": "FoVFXpPq8L7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter1 = re.finditer('[\\d]', '1ab 2cd 3ef 4g')\n",
        "print(iter1)\n",
        "for i in iter1:\n",
        "  print(i)\n",
        "\n",
        "iter2 = re.finditer('[\\W]', '!abcd@@#')\n",
        "print(iter2)\n",
        "for i in iter2:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn4ilMBr76F5",
        "outputId": "d6433862-fc99-45b0-fdd6-9b915ede0985"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<callable_iterator object at 0x7f3a848f0710>\n",
            "<re.Match object; span=(0, 1), match='1'>\n",
            "<re.Match object; span=(4, 5), match='2'>\n",
            "<re.Match object; span=(8, 9), match='3'>\n",
            "<re.Match object; span=(12, 13), match='4'>\n",
            "<callable_iterator object at 0x7f3a848f08d0>\n",
            "<re.Match object; span=(0, 1), match='!'>\n",
            "<re.Match object; span=(5, 6), match='@'>\n",
            "<re.Match object; span=(6, 7), match='@'>\n",
            "<re.Match object; span=(7, 8), match='#'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 토큰화(Tokenization)\n",
        "- 특수문자에 대한 처리\n",
        "  - 단어에 일반적으로 사용되는 알파벳, 숫자와는 다르게 특수문자는 별도의 처리가 필요\n",
        "  - 일괄적으로 단어의 특수문자를 제거하는 방법도 있지만, 특수문자가 단어에 특별한 의미를가질 때, 이를 학습에 반영시키지 못 할 수도 있음\n",
        "  - 특수문자에 대한 일괄적인 제거보다는 데이터의 특성을 파악하고, 처리하는 것이 중요\n",
        "- 특정단어에 대한 토큰 분리 방법\n",
        "  - 한 단어지만 토큰으로 분리할 때, 판단되는 문자들로 이루어진 we're, United Kingdom 등의 단어는 어떻게 분리해야 할 지 선택 필요\n",
        "  - we're은 한 단어이나, 분리해도 단어의 의미에 별 영향을 끼치진 않지만, United Kingdom은 두 단어가 모여 특정 의미를 가리켜 분리해선 안 됨\n",
        "  - 사용자가 단어의 특성을 고려해, 토컨을 분리하는 것이 학습에 유리"
      ],
      "metadata": {
        "id": "ggNO18Vc8Iwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단어 토큰화\n",
        "- 파이썬 내장 함수인 split을 활용해 단어 토큰화\n",
        "- 공백을 기준으로 단어를 분리"
      ],
      "metadata": {
        "id": "lZjhYJKj7Ugf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Time is gold'\n",
        "tokens = [x for x in sentence.split(' ')]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLp0jwSH7Vla",
        "outputId": "1b2da15b-2930-4325-8b04-9a077ed0e3da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Time', 'is', 'gold']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 토큰화는 **nltk** 패키지의 **tokenize** 모듈을 사용해, 손쉽게 구현 가능\n",
        "- 단어 토큰화는 **word_tokenize()** 함수를 사용해 구현 가능"
      ],
      "metadata": {
        "id": "ARmsl7fN8SOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3gOpc1i8ihw",
        "outputId": "7402ac65-f171-4071-a19b-d52b9452e9a7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ghQzSe2619W",
        "outputId": "2d82e88a-cc37-4bb6-f713-9d50ed760a68"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Time', 'is', 'gold']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문장 토큰화\n",
        "- 문장 토큰화는 줄바꿈 문자('\\n')를 기준으로 문장을 분리"
      ],
      "metadata": {
        "id": "bElRYbwf89J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = 'The world is a beautiful book.\\nBut of little use to him who cannot read it.'\n",
        "print(sentences)\n",
        "\n",
        "tokens = [x for x in sentences.split('\\n')]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYnFbdMC81Js",
        "outputId": "2ded1161-6f5b-4bfc-9510-799a5c8b4a46"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The world is a beautiful book.\n",
            "But of little use to him who cannot read it.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The world is a beautiful book.',\n",
              " 'But of little use to him who cannot read it.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장 토큰화에서는 온점(.)의 처리를 위해 이진 분류기를 사용할 수도 있음\n",
        "- 온점은 문장과 문장을 구분해줄 수도, 문장에 포함된 단어를 구성할 수도 있기 때문에, 이를 이진 분류기로 분류해 더욱 좋은 토큰화를 구현할 수도 있음"
      ],
      "metadata": {
        "id": "bXEUn6t2-LFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정규 표현식을 이용한 토큰화\n",
        "- 토큰화 기능을 직접 구현할 수도 있지만, 정규 표현식을 이용해 간단하게 구현할 수도 있음\n",
        "- nltk 패키지는 정규 표현식을 사용하는 토큰화 도구인 **RegexpTokenizer**를 제공"
      ],
      "metadata": {
        "id": "yMyQuTwr-365"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "sentence = 'Where there\\'s a will, there\\'s a way'\n",
        "\n",
        "tokenizer = RegexpTokenizer(\"[\\w]+\") \n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N454v6A9Tlq",
        "outputId": "b4276a1b-878d-4a24-9f3e-ac9fe5dd2e67"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Where', 'there', 's', 'a', 'will', 'there', 's', 'a', 'way']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문자와 숫자가 최소 1개 이상 있는 것을 의미 => **'[\\w]+'**"
      ],
      "metadata": {
        "id": "mpIWxW7hBLmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(\"[\\s]+\", gaps=True)\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBeyeG-ZANlY",
        "outputId": "0af67759-49ca-4375-b86c-81ebcfce34f9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Where', \"there's\", 'a', 'will,', \"there's\", 'a', 'way']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "특수문자가 포함된 결과를 반환, 공백으로 토큰화=> **\"[\\s]\", gaps=True**"
      ],
      "metadata": {
        "id": "pI5uEhukBina"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 케라스를 이용한 토큰화"
      ],
      "metadata": {
        "id": "Khno-4fyCEsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence = 'Where there\\'s a will, there\\'s a way'\n",
        "\n",
        "text_to_word_sequence(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNdAHsXxCHNq",
        "outputId": "d8517dfc-475c-4d54-f38d-8f07aaed6420"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['where', \"there's\", 'a', 'will', \"there's\", 'a', 'way']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextBlob을 이용한 토큰화"
      ],
      "metadata": {
        "id": "FaebQXYOCgIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  from textblob import TextBlob\n",
        "\n",
        "  sentence = 'Where there\\'s a will, there\\'s a way'\n",
        "\n",
        "  blob = TextBlob(sentence)\n",
        "  blob.words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEc-2yuICVe8",
        "outputId": "1f612c02-53e5-4c7c-e7c8-b19afbe58717"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['Where', 'there', \"'s\", 'a', 'will', 'there', \"'s\", 'a', 'way'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기타 토크나이저\n",
        "- WhiteSpaceTokenizer: 공백을 기준으로 토큰화\n",
        "- WordPunkTokenizer: 텍스트를 알파벳 문자, 숫자, 알파벳 이외의 문자 리스트로 토큰화\n",
        "- MWETokenizer: MWE는 Multi-Word Expression의 약자로, 'republic of korea'와 같이 여러 단어로 이뤄진 특정 그룹을 한 개체로 취급\n",
        "- TweetTokenizer: 트위터에서 사용되는 문장의 토큰화를 위해서 만들어졌으며, 문장 속 감성의 표현과 감정을 다룸"
      ],
      "metadata": {
        "id": "QP441GtFDS8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# n-gram 추출\n",
        "- n-gramdms n개의 어절이나, 음절을 연쇄적으로 분류해, 그 빈도를 분석\n",
        "- n=1일 때는, unigram, n=2일 때는, bigram, n=3일 때는, trigram으로 불림"
      ],
      "metadata": {
        "id": "VCglhIrPDxzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "sentence = 'There is no royal road to learning'\n",
        "bigram = list(ngrams(sentence.split(), 2))\n",
        "print(bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkjZOKfrCySX",
        "outputId": "51d76686-ff20-4e62-a806-609f95ed74b8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('There', 'is'), ('is', 'no'), ('no', 'royal'), ('royal', 'road'), ('road', 'to'), ('to', 'learning')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram = list(ngrams(sentence.split(), 3))\n",
        "print(trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18l46OwAEj4j",
        "outputId": "af56363c-2d56-4f68-9190-d5975dbb7e5f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('There', 'is', 'no'), ('is', 'no', 'royal'), ('no', 'royal', 'road'), ('royal', 'road', 'to'), ('road', 'to', 'learning')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "blob = TextBlob(sentence)\n",
        "blob.ngrams(n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6wjUms2E9hV",
        "outputId": "06709600-3e14-4c26-cb47-b75d6c15723f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['There', 'is']),\n",
              " WordList(['is', 'no']),\n",
              " WordList(['no', 'royal']),\n",
              " WordList(['royal', 'road']),\n",
              " WordList(['road', 'to']),\n",
              " WordList(['to', 'learning'])]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.ngrams(n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VjIAFiIFDOo",
        "outputId": "98e55859-a41d-4c07-bb79-7c6a28a50534"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['There', 'is', 'no']),\n",
              " WordList(['is', 'no', 'royal']),\n",
              " WordList(['no', 'royal', 'road']),\n",
              " WordList(['royal', 'road', 'to']),\n",
              " WordList(['road', 'to', 'learning'])]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PoS(Parts of Speech) 태깅\n",
        "- PoS는 품사를 의미하며, PoS 태깅은 문장 내에서 단어에 해당하는 각 품사를 태깅"
      ],
      "metadata": {
        "id": "I21RmGnaFRgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFEqgoUlFPhg",
        "outputId": "53c1a391-1c39-41f5-a87f-13c04f3d1905"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(\"Think like man of action and act like man of thought.\")\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uN7EYCwFlsl",
        "outputId": "c163c346-5cf5-4eac-8b78-2e6604969a88"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Think',\n",
              " 'like',\n",
              " 'man',\n",
              " 'of',\n",
              " 'action',\n",
              " 'and',\n",
              " 'act',\n",
              " 'like',\n",
              " 'man',\n",
              " 'of',\n",
              " 'thought',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "nltk.pos_tag(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyz-kIHAFt07",
        "outputId": "9eb83f1a-cf80-4161-e293-85cfe9b80f28"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Think', 'VBP'),\n",
              " ('like', 'IN'),\n",
              " ('man', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('action', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('act', 'NN'),\n",
              " ('like', 'IN'),\n",
              " ('man', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('thought', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(word_tokenize(\"a rolling stone gathers no moss\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6ayUJF7F6PK",
        "outputId": "137fe64e-ff0b-464d-8425-4bffc873c785"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'DT'),\n",
              " ('rolling', 'VBG'),\n",
              " ('stone', 'NN'),\n",
              " ('gathers', 'NNS'),\n",
              " ('no', 'DT'),\n",
              " ('moss', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- PoS 태그 리스트\n",
        "\n",
        "| Number | Tag | Description | 설명 |\n",
        "| -- | -- | -- | -- |\n",
        "| 1 | `CC` | Coordinating conjunction |\n",
        "| 2 | `CD` | Cardinal number |\n",
        "| 3 | `DT` | Determiner | 한정사\n",
        "| 4 | `EX` | Existential there |\n",
        "| 5 | `FW` | Foreign word | 외래어 |\n",
        "| 6 | `IN` | Preposition or subordinating conjunction | 전치사 또는 종속 접속사 |\n",
        "| 7 | `JJ` | Adjective | 형용사 |\n",
        "| 8 | `JJR` | Adjective, comparative | 헝용사, 비교급 |\n",
        "| 9 | `JJS` | Adjective, superlative | 형용사, 최상급 |\n",
        "| 10 | `LS` | List item marker |\n",
        "| 11 | `MD` | Modal |\n",
        "| 12 | `NN` | Noun, singular or mass | 명사, 단수형 |\n",
        "| 13 | `NNS` | Noun, plural | 명사, 복수형 |\n",
        "| 14 | `NNP` | Proper noun, singular | 고유명사, 단수형 |\n",
        "| 15 | `NNPS` | Proper noun, plural | 고유명사, 복수형 |\n",
        "| 16 | `PDT` | Predeterminer | 전치한정사 |\n",
        "| 17 | `POS` | Possessive ending | 소유형용사 |\n",
        "| 18 | `PRP` | Personal pronoun | 인칭 대명사 |\n",
        "| 19 | `PRP$` | Possessive pronoun | 소유 대명사 |\n",
        "| 20 | `RB` | Adverb | 부사 |\n",
        "| 21 | `RBR` | Adverb, comparative | 부사, 비교급 |\n",
        "| 22 | `RBS` | Adverb, superlative | 부사, 최상급 |\n",
        "| 23 | `RP` | Particle |\n",
        "| 24 | `SYM` | Symbol | 기호\n",
        "| 25 | `TO` | to |\n",
        "| 26 | `UH` | Interjection | 감탄사 |\n",
        "| 27 | `VB` | Verb, base form | 동사, 원형 |\n",
        "| 28 | `VBD` | Verb, past tense | 동사, 과거형 |\n",
        "| 29 | `VBG` | Verb, gerund or present participle | 동사, 현재분사 |\n",
        "| 30 | `VBN` | Verb, past participle | 동사, 과거분사 |\n",
        "| 31 | `VBP` | Verb, non-3rd person singular present | 동사, 비3인칭 단수 |\n",
        "| 32 | `VBZ` | Verb, 3rd person singular present | 동사, 3인칭 단수 |\n",
        "| 33 | `WDT` | Wh-determiner |\n",
        "| 34 | `WP` | Wh-pronoun |\n",
        "| 35 | `WP$` | Possessive wh-pronoun |\n",
        "| 36 | `WRB` | Wh-adverb |"
      ],
      "metadata": {
        "id": "sXahl0zDGnBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 불용어 제거\n",
        "- 영어의 전치사, 한국어의 조사 등은 분석에 필요하지 않은 경우가 많음\n",
        "- 길이가 짧은 단어, 등장 빈도 수가 적은 단어들도 분석에 큰 영향을 주지 않음\n",
        "- 일반적으로 사용되는 도구들은 해당 단어들을 제거해주지만, 완벽하게 제거되지는 않음\n",
        "- 상용자가 불용어 사전을 만들어, 해당 단어들을 제거하는 것이 좋음\n",
        "- 도구들이 걸러주지 않는 전치사, 조사 등을 불용어 사전을 만들어 불필요한 단어들을 제거"
      ],
      "metadata": {
        "id": "C0lVxfCbH0hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " stop_words = \"on in the\"\n",
        " stop_wrods = stop_words.split(\" \")\n",
        " stop_wrods"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edLXT2SHGG0I",
        "outputId": "44453d60-e573-4051-f496-d50bb5d9702d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['on', 'in', 'the']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'singer on the stage'\n",
        "sentence = sentence.split(\" \")\n",
        "nouns = []\n",
        "for noun in sentence:\n",
        "  if noun not in stop_words:\n",
        "    nouns.append(noun)\n",
        "\n",
        "nouns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpp_SmyVIYzK",
        "outputId": "3957ad2e-a4d2-4ac0-9149-05652730da0e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['singer', 'stage']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **nltk**패키지에 불용어 리스트 사용"
      ],
      "metadata": {
        "id": "PXGL_qNlI6oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk import wordpunct_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTzD1f4QIl_z",
        "outputId": "003d6f1b-26c0-4c59-bda3-7b00fc26119c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHOIwCFaJNGs",
        "outputId": "fdcdd401-ee88-4bbe-c00e-4686cf3e49bb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = 'If you do not walk today, you will have to run tomorrow.'\n",
        "words = word_tokenize(s)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DNXuWxoJU6N",
        "outputId": "30b72ac9-c877-447e-9c89-3388fa9e0287"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['If', 'you', 'do', 'not', 'walk', 'today', ',', 'you', 'will', 'have', 'to', 'run', 'tomorrow', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_stopwords = []\n",
        "for w in words:\n",
        "  if w not in stop_words:\n",
        "    no_stopwords.append(w)\n",
        "\n",
        "print(no_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0ctqfdSJjdx",
        "outputId": "1d441579-63dc-4df3-9a13-8ca10a7a14fc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['If', 'walk', 'today', ',', 'run', 'tomorrow', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 철자 교정\n",
        "- 텍스트에 오탈자가 존재하는 경우가 있음\n",
        "- 예를 들어, 단어 'apple'을 'aplpe'과 같이 철자 순서가 바뀌거나, spple 같이 철자가 틀릴 수 있음\n",
        "- 사람이 적절한 추정을 통해 이해하는데는 문제가 없지만, 컴퓨터는 이러한 단어를 그대로 받아들여 처리가 필요\n",
        "- 철자 교정 알고리즘은 이미 개발되어, 워드 프로세서나 다양한 서비스에서 많이 적용됨"
      ],
      "metadata": {
        "id": "mN7zvD6EJ6_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autocorrect\n",
        "from autocorrect import Speller"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_CQkqYHJv_2",
        "outputId": "6247ebe2-664a-46e6-d46a-4deabb0b86f0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[K     |████████████████████████████████| 622 kB 5.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=e28e98812cc849748a12f8fba8ec9c2d83a04024fa525d9292a6a191a87b7040\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spell = Speller('en')\n",
        "\n",
        "print(spell('peoplle'))\n",
        "print(spell('peope'))\n",
        "print(spell('peopae'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp6fGZCB5Hmw",
        "outputId": "5aa4a0e7-d782-432e-a163-52851c729941"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "people\n",
            "people\n",
            "people\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = word_tokenize(\"Earlly bird catchess the womm.\")\n",
        "print(s)\n",
        "ss = ' '.join([spell(s) for s in s])\n",
        "print(ss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXC4lEnN5UIC",
        "outputId": "8ae3777a-b089-4149-891c-521c09e15cb3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Earlly', 'bird', 'catchess', 'the', 'womm', '.']\n",
            "Early bird catches the worm .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 언어의 단수화와 복수화"
      ],
      "metadata": {
        "id": "Mm0fY7HA6OQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textblob\n",
        "from textblob import TextBlob\n",
        "\n",
        "words = 'apples bananas oranges'\n",
        "tb = TextBlob(words)\n",
        "\n",
        "print(tb.words)\n",
        "print(tb.words.singularize())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0CbHlTd5gj5",
        "outputId": "96a94df1-9273-4d82-e6aa-e6d2741f89c1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apples', 'bananas', 'oranges']\n",
            "['apple', 'banana', 'orange']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = 'car train airplane'\n",
        "tb = TextBlob(words)\n",
        "\n",
        "print(tb.words)\n",
        "print(tb.words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_TjCorx6kRY",
        "outputId": "df09bbaf-bce5-4402-d187-c923b9dfca98"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['car', 'train', 'airplane']\n",
            "['car', 'train', 'airplane']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 어간(Stemming)추출"
      ],
      "metadata": {
        "id": "IKxEzo4nkiQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "\n",
        "stemmer.stem('application')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2kHoX2gKkoS3",
        "outputId": "d7945a14-7f64-408b-c94b-81a4b6e21913"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'applic'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('catches')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nDGwtC4ak9U2",
        "outputId": "73a7e74f-d74e-47b4-fe8d-b7860356bb4e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'catch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('education')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WfrTonpvlBgb",
        "outputId": "d0323227-e9d1-4fca-a565-066aebbfd127"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'educ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 표제어(Lemmatization) 추출"
      ],
      "metadata": {
        "id": "-8MFCZqdlJQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# nltk.download('all')\n",
        "nltk.download('popular')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy2IOHaUlF8T",
        "outputId": "6742d62c-08c4-42d2-a00c-02ece484cbe4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('application')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "A2Gp8hbomjCx",
        "outputId": "84a0e8a7-9b2d-450d-a1c4-e7bc92e64cd5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'application'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('beginning')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gCJlEJptm4E6",
        "outputId": "81989ba0-6555-427c-d7d3-32e9c0cff152"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'beginning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('catches')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OXuB3vdLrrQ4",
        "outputId": "3339e58b-a38e-4797-a155-802ce1839aa7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'catch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('education')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CDdYkmdzrvl0",
        "outputId": "b103fbac-03b3-47b0-a2b2-328939f85c60"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'education'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 개체명 인식(Named Entity Recognition)"
      ],
      "metadata": {
        "id": "t6whEQf9r43M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vjIacD0r3Rb",
        "outputId": "9aeb74da-5dd3-4587-8c0f-ba55e610a9f8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Rome was not built in a day.\"\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqcgFTxVsLeg",
        "outputId": "cadde10e-0ed8-4840-945e-d42bae62e36f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rome was not built in a day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = nltk.pos_tag(word_tokenize(s))\n",
        "print(tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUw8NZZRsQ4b",
        "outputId": "3c98a401-800a-488f-e57a-5340f32d407f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Rome', 'NNP'), ('was', 'VBD'), ('not', 'RB'), ('built', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('day', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entities = nltk.ne_chunk(tags, binary=True)\n",
        "print(entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4gkv90tsYBa",
        "outputId": "122324d6-c7c8-4941-a783-423f29bd5b00"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (NE Rome/NNP) was/VBD not/RB built/VBN in/IN a/DT day/NN ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단어 중의성(Lexical Ambiguity)"
      ],
      "metadata": {
        "id": "myLc3HfMsxsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.wsd import lesk\n",
        "\n",
        "s = \"I saw bats.\"\n",
        "\n",
        "print(word_tokenize(s))\n",
        "print(lesk(word_tokenize(s), 'saw'))\n",
        "print(lesk(word_tokenize(s), 'bats'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruKeFutNsfzI",
        "outputId": "1cc5fbaf-e94e-465b-9016-5aff1dfe2ce6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'saw', 'bats', '.']\n",
            "Synset('saw.v.01')\n",
            "Synset('squash_racket.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "나는 야구 방망이를 잘랐다.\n",
        "\n",
        "나는 박쥐를 보았다.\n",
        "\n",
        "나는 야구 방망이를 보았다.\n",
        "\n",
        "=> 여러가지로 해석 될 수 있음"
      ],
      "metadata": {
        "id": "cOl0607rtFi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 한국어 처리"
      ],
      "metadata": {
        "id": "xk2wPTtwtjuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정규표현식\n",
        "- 한국어 정규 표현식도 대부분의 문법은 영어 정규 표현식과 같음\n",
        "- 한국어는 자음과 모음이 분리되어 있기 때문에, 문법을 지정할 대는 자음과 모음을 동시에 고려해야 함"
      ],
      "metadata": {
        "id": "2XLanvhXuA7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# match\n",
        "- 컴파일한 정규 표현식을 이용해 문자열이 정규 표현식과 맞는지 검사"
      ],
      "metadata": {
        "id": "QA7lqIXAuJNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "check = '[ㄱ-ㅎ]+'\n",
        "\n",
        "print(re.match(check, 'ㅎ 안녕하세요.'))\n",
        "print(re.match(check, '안녕하세요. ㅎ'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1VclxV-uQe-",
        "outputId": "633c8519-bf90-4744-829d-5041b8996263"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 1), match='ㅎ'>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check2 = '[ㄱ-ㅎ]'\n",
        "print(re.match(check, 'ㅎ 안녕하세요.'))\n",
        "print(re.match(check, '안녕하세요. ㅎ'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jndriV0xukM8",
        "outputId": "b9e1f820-8dd0-4fcb-bd8c-11ee5b4323d7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 1), match='ㅎ'>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "희안하네... 왜 안되냐..."
      ],
      "metadata": {
        "id": "5gj1D3sMvVeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# search\n",
        "- match와 다르게, search는 문자열의 전체를 검사"
      ],
      "metadata": {
        "id": "yDvxheghvUAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check = '[ㄱ-ㅎ|ㅏ-ㅣ]+'\n",
        "\n",
        "print(re.search(check, 'ㄱ ㅏ  안녕하세요'))\n",
        "print(re.match(check, '안 ㄱ ㅏ'))\n",
        "print(re.match(check, 'ㄱ ㅏ안'))\n",
        "print(re.search(check, '안 ㄱ ㅏ'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJjmF4Drut60",
        "outputId": "15dbd7b2-9a88-4929-f24f-fdae690d92b8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 1), match='ㄱ'>\n",
            "None\n",
            "<re.Match object; span=(0, 1), match='ㄱ'>\n",
            "<re.Match object; span=(2, 3), match='ㄱ'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sub\n",
        "- 정규 표현식과 일치하는 부분을 다른 문자열로 교체"
      ],
      "metadata": {
        "id": "kN-LtfnewQwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(re.sub('[가-힣]', '가나다라마바사', '1'))\n",
        "print(re.sub('[^가-힣]', '가나다라마바사', '1'))\n",
        "print(re.sub('[ㄱ-ㅎ|ㅏ-ㅣ]', '가나닿ㅎㅎㅎㅎㅎㅏㅏㅏ', '1'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-DT_UTYv42a",
        "outputId": "bd2cd6d2-59c7-4f9f-cf53-1bb8e0a7d111"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "가나다라마바사\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 토큰화(Tokenization)\n",
        "- 한국어를 학습 데이터를 사용할 때는, 언어의 특성으로 인해, 추가로 고려해야 할 사항이 존재\n",
        "- 한국어는 띄어쓰기를 준수하지 않아도 의미가 전달되는 경우가 많아, 띄어쓰기가 지켜지지 않을 가능성이 존재\n",
        "- 띄어쓰기가 지켜지지 않으면, 정상적인 토큰 분리가 이루어지지 않음\n",
        "- 한국어는 형태소라는 개념이 존재해 추가로 고려해주어야만 함\n",
        "- '그는', '그가' 등의 단어들은 같은 의미를 가리키지만, 텍스트 처리에서는 다르게 받아들일 수 있어, 처리를 해 주어야 함"
      ],
      "metadata": {
        "id": "0Zx_6AiJxVP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 한국어 자연어 처리 konlpy와 형태소 분석기 MeCab 설치\n",
        "- https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh"
      ],
      "metadata": {
        "id": "KPA8nXZNxyMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!set -x \\\n",
        "&& pip install konlpy \\\n",
        "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x"
      ],
      "metadata": {
        "id": "3yjtCNzcw5Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단어 토큰화\n",
        "* 한국어는 공백으로 단어를 분리해도 조사, 접속사 등이 남아 분석에 어려움이 있음\n",
        "* 이를 해결해주는 한국어 토큰화는 조사, 접속사를 분리해주거나 제거\n",
        "* 한국어 토큰화를 사용하기 위해선 `konlpy`와 `mecab`이라는 라이브러리가 필요"
      ],
      "metadata": {
        "id": "vrSeTQdHymUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "tagger = Mecab()"
      ],
      "metadata": {
        "id": "vnUThl81yeZj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence = '언제나 현재에 집중할 수 있다면 행복할 것이다.?🍌!!!!!'\n",
        "sentence = '로미 졸귀탱 아이 귀여웟 빠가야로'\n",
        "test = tagger.pos(sentence)\n",
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIX0Httjyrt5",
        "outputId": "0d9fbb4a-3af5-44b5-8a2d-888a6c5c7993"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('로미', 'NNP'),\n",
              " ('졸', 'NNG'),\n",
              " ('귀', 'NNG'),\n",
              " ('탱', 'NNG'),\n",
              " ('아이', 'NNG'),\n",
              " ('귀여', 'NNP'),\n",
              " ('웟', 'UNKNOWN'),\n",
              " ('빠', 'NNP'),\n",
              " ('가', 'JKS'),\n",
              " ('야로', 'NNG')]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 토큰화만 실행할 때는 `tagger.morphs()`라는 함수를 이용"
      ],
      "metadata": {
        "id": "g3pIac3tyxDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.morphs(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZQOpYKiyyBX",
        "outputId": "e579c535-e22e-4230-a9f6-35096ed1303d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['언제나',\n",
              " '현재',\n",
              " '에',\n",
              " '집중',\n",
              " '할',\n",
              " '수',\n",
              " '있',\n",
              " '다면',\n",
              " '행복',\n",
              " '할',\n",
              " '것',\n",
              " '이',\n",
              " '다',\n",
              " '.',\n",
              " '?',\n",
              " '🍌',\n",
              " '!',\n",
              " '!!!!']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 형태소만 사용하고 싶을 때는 `tagger.nouns()`라는 함수를 이용해 조사, 접속사 등을 제거 가능"
      ],
      "metadata": {
        "id": "ZGUQLgANyyZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.nouns(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRDFw-vTy4Zv",
        "outputId": "bd91cccd-f7e9-4a61-9b14-12559133115f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['로미', '졸', '귀', '탱', '아이', '귀여', '빠', '야로']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문장 토큰화\n",
        "- 한국어 문장을 토큰화할 때는 kss(korean sentence splitter) 라이브러리 이용"
      ],
      "metadata": {
        "id": "LSpuNjqgy3hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install kss==2.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnwvjnpAy_z7",
        "outputId": "8498ccd0-a2c2-43da-8def-064f22d4182f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kss==2.6.0\n",
            "  Downloading kss-2.6.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: kss\n",
            "Successfully installed kss-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 라이브러리를 이용해도 한국어에는 전치 표현이 존재해 제대로 토큰화가 안됨\n",
        "* 좀 더 나은 학습을 위해 사용자는 해당 부분을 따로 처리해주어야만 함"
      ],
      "metadata": {
        "id": "A_pd6RrQzAFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "\n",
        "text = '진짜? 내일 뭐하지. 이렇게 애매모호한 문장도? 밥은 먹었어? ㅎㅎ 나는... ㅠㅠ'\n",
        "print(kss.split_sentences(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOl94FvfzCcl",
        "outputId": "514efe2d-3f0d-43c1-ffa6-87c5dcdf035f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['진짜? 내일 뭐하지.', '이렇게 애매모호한 문장도? 밥은 먹었어? ㅎㅎ', '나는... ㅠㅠ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정규 표현식을 이용한 토큰화\n",
        "- 한국어도 정규 표현식을 이용해 토큰화 가능"
      ],
      "metadata": {
        "id": "sPM6J3YMzElT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "sentence = '안녕하세요 ㅋㅋ 저는 자연어 처리(Natural Language Processing)를ㄹ!! 배우고 있습니다.???🍅'\n",
        "\n",
        "tokenizer = RegexpTokenizer('[가-힣]+')\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0dS60W_zLgB",
        "outputId": "d2f28f6b-6d1f-48a6-9c9b-e9dd691695a9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['안녕하세요', '저는', '자연어', '처리', '를', '배우고', '있습니다']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 케라스를 이용한 토큰화"
      ],
      "metadata": {
        "id": "8B2K-dYAzL_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence = '성공의 비결은 단 한 가지, 잘 할 수 있는 일에 광적으로 집중하는 것이다.😀'\n",
        "\n",
        "text_to_word_sequence(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae4b8lqszO7q",
        "outputId": "570dc5f0-9146-42aa-9534-a4f97735514e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['성공의',\n",
              " '비결은',\n",
              " '단',\n",
              " '한',\n",
              " '가지',\n",
              " '잘',\n",
              " '할',\n",
              " '수',\n",
              " '있는',\n",
              " '일에',\n",
              " '광적으로',\n",
              " '집중하는',\n",
              " '것이다',\n",
              " '😀']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextBlob을 이용한 토큰화"
      ],
      "metadata": {
        "id": "oBGgZDr6zQ_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "blob = TextBlob(sentence)\n",
        "blob.words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5QQW_OczTF5",
        "outputId": "ed9f2805-c29e-427c-969b-a930b01ab436"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['성공의', '비결은', '단', '한', '가지', '잘', '할', '수', '있는', '일에', '광적으로', '집중하는', '것이다.😀'])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words(BoW)"
      ],
      "metadata": {
        "id": "RtySjFXJzTr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = ['Think like a man of action and act like man of thought.']\n",
        "\n",
        "vector = CountVectorizer()\n",
        "bow = vector.fit_transform(corpus)\n",
        "\n",
        "print(bow.toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLHqkDGLzW6t",
        "outputId": "f42f26d7-1c7e-4125-bd8b-296a7c26ea78"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 2 2 2 1 1]]\n",
            "{'think': 6, 'like': 3, 'man': 4, 'of': 5, 'action': 1, 'and': 2, 'act': 0, 'thought': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = CountVectorizer(stop_words='english')\n",
        "bow = vector.fit_transform(corpus)\n",
        "\n",
        "print(bow.toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA-1xH1yzXrL",
        "outputId": "c2449316-744d-4b34-d3eb-89f7ec01e727"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 2 2 1 1]]\n",
            "{'think': 4, 'like': 2, 'man': 3, 'action': 1, 'act': 0, 'thought': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['평생 살 것처럼 꿈을 꾸어라. 그리고 내일 죽을 것처럼 오늘을 살아라. 😀']\n",
        "vector = CountVectorizer()\n",
        "bow = vector.fit_transform(corpus)\n",
        "\n",
        "print(bow.toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdhFNDORzXe7",
        "outputId": "9a12eb32-4ad8-400d-fb88-21e30440ab0e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 1 1 1 1 1 1 1 1]]\n",
            "{'평생': 8, '것처럼': 0, '꿈을': 3, '꾸어라': 2, '그리고': 1, '내일': 4, '죽을': 7, '오늘을': 6, '살아라': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from konlpy.tag import Mecab\n",
        "tagger = Mecab()\n",
        "\n",
        "corpus ='진짜? 내일 뭐하지. 이렇게 애매모호한 문장도? 밥은 먹었어? ㅎㅎ 나는... ㅠㅠ'\n",
        "tokens = tagger.morphs(re.sub(\"(\\.)\", \"\", corpus))\n",
        "\n",
        "vocab = {}\n",
        "bow = []\n",
        "\n",
        "for tok in tokens:\n",
        "  if tok not in vocab.keys():\n",
        "    vocab[tok] = len(vocab)\n",
        "    bow.insert(len(vocab)-1, 1)\n",
        "  else:\n",
        "    index = vocab.get(tok)\n",
        "    bow[index] = bow[index]+1\n",
        "\n",
        "print(bow)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4cizlLNzXSJ",
        "outputId": "5a410992-828c-4362-e4cf-8d50067b4e4f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "{'진짜': 0, '?': 1, '내일': 2, '뭐': 3, '하': 4, '지': 5, '이렇게': 6, '애매': 7, '모호': 8, '한': 9, '문장': 10, '도': 11, '밥': 12, '은': 13, '먹': 14, '었': 15, '어': 16, 'ㅎㅎ': 17, '나': 18, '는': 19, 'ㅠㅠ': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문서 단어 행렬(DTM)\n",
        "* 문서 단어 행렬(Document-Term Matrix)은 문서에 등장하는 여러 단어들의 빈도를 행렬로 표현\n",
        "* 각 문서에 대한 BoW를 하나의 행렬로 표현한 것"
      ],
      "metadata": {
        "id": "kpArFgMXzaWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\"Think like a man action and act like man of thought.\",\n",
        "          \"Try not to become a man of success but rather try to become a man of value.\",\n",
        "          \"Give me liberty, of give me death\"]\n",
        "\n",
        "vector = CountVectorizer(stop_words='english')\n",
        "bow = vector.fit_transform(corpus)\n",
        "\n",
        "print(bow.toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "metadata": {
        "id": "LBjY6_igzfK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ff08a7-cd0f-40a4-9886-b4859847428e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 0 0 2 2 0 1 1 0 0]\n",
            " [0 0 0 0 0 2 1 0 0 2 1]\n",
            " [0 0 1 1 0 0 0 0 0 0 0]]\n",
            "{'think': 7, 'like': 4, 'man': 5, 'action': 1, 'act': 0, 'thought': 8, 'try': 9, 'success': 6, 'value': 10, 'liberty': 3, 'death': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 결과를 한 눈에 보기 쉽도록 아래와 같이 보여줌"
      ],
      "metadata": {
        "id": "biqLxUPKlJSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "columns = []\n",
        "for k, v in sorted(vector.vocabulary_.items(), key=lambda item:item[1]) :\n",
        "  columns.append(k)\n",
        "\n",
        "df = pd.DataFrame(bow.toarray(), columns=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "q7HoE8eykTOr",
        "outputId": "71df5d13-807e-4a49-fe5d-e7723186aa7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   act  action  death  liberty  like  man  success  think  thought  try  value\n",
              "0    1       1      0        0     2    2        0      1        1    0      0\n",
              "1    0       0      0        0     0    2        1      0        0    2      1\n",
              "2    0       0      1        1     0    0        0      0        0    0      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55eb0fbe-ee41-4ee9-8736-226f38435333\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>death</th>\n",
              "      <th>liberty</th>\n",
              "      <th>like</th>\n",
              "      <th>man</th>\n",
              "      <th>success</th>\n",
              "      <th>think</th>\n",
              "      <th>thought</th>\n",
              "      <th>try</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55eb0fbe-ee41-4ee9-8736-226f38435333')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55eb0fbe-ee41-4ee9-8736-226f38435333 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55eb0fbe-ee41-4ee9-8736-226f38435333');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 어휘 빈도-문서 역빈도(TF-IDF) 분석\n",
        "* 어휘 빈도-문서 역빈도(TF-IDF; Term Frequency-Inverse Docunment Frequency)는 단순히 빈도수가 높은 단어가 핵심어가 아닌, 특정 문서에서만 집중적으로 등장할 때 해당 단어가 문서의 주제를 잘 담고 있는 핵심어라고 가정\n",
        "* 특정 문서에서 특정단어가 많이 등장하고 그 단어가 다른 문서에서 적게 등장할 때, 그 단어를 특정 문서의 핵심어로 간주\n",
        "* 어휘 빈도-문서 역빈도는 어휘 빈도와 역문서 빈도를 곱해 계산 가능\n",
        "* **역문서 빈도**는 다른 문서에서 등장하지 않는 단어 빈도를 의미\n",
        "\n",
        "$$ log(N/df_x) $$   \n",
        "* **어휘 빈도-문서 역빈도**는 다음과 같이 표현\n",
        "\n",
        "$$ W_{x,y} = tf_{x,y} * log(N/df_x) $$\n",
        "* tf-idf를 편리하게 계산하기 위해 `scikit-learn`의 `tfidfvectorizer`를 이용\n",
        "* 앞서 계산한 단어 빈도 수를 입력하여 tf-idf로 변환"
      ],
      "metadata": {
        "id": "-HCbYVm3zfhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english').fit(corpus)\n",
        "\n",
        "print(tfidf.transform(corpus).toarray())\n",
        "print(tfidf.vocabulary_)"
      ],
      "metadata": {
        "id": "IR07Iq31zqxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb43e649-2f98-4db4-be54-a4437f945979"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.311383   0.311383   0.         0.         0.62276601 0.4736296\n",
            "  0.         0.311383   0.311383   0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.52753275\n",
            "  0.34682109 0.         0.         0.69364217 0.34682109]\n",
            " [0.         0.         0.70710678 0.70710678 0.         0.\n",
            "  0.         0.         0.         0.         0.        ]]\n",
            "{'think': 7, 'like': 4, 'man': 5, 'action': 1, 'act': 0, 'thought': 8, 'try': 9, 'success': 6, 'value': 10, 'liberty': 3, 'death': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 좀 더 편리하게 확인하기 위해 데이터프레임으로 변환"
      ],
      "metadata": {
        "id": "75Z3IrVzzsnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = []\n",
        "for k, v in sorted(tfidf.vocabulary_.items(), key=lambda item:item[1]) :\n",
        "  columns.append(k)\n",
        "\n",
        "pd.DataFrame(tfidf.transform(corpus).toarray(), columns=columns)"
      ],
      "metadata": {
        "id": "j7YH22WpztNn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "331a0f6e-be71-4216-83ac-c60e3769db1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        act    action     death   liberty      like       man   success  \\\n",
              "0  0.311383  0.311383  0.000000  0.000000  0.622766  0.473630  0.000000   \n",
              "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.527533  0.346821   \n",
              "2  0.000000  0.000000  0.707107  0.707107  0.000000  0.000000  0.000000   \n",
              "\n",
              "      think   thought       try     value  \n",
              "0  0.311383  0.311383  0.000000  0.000000  \n",
              "1  0.000000  0.000000  0.693642  0.346821  \n",
              "2  0.000000  0.000000  0.000000  0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-006a773b-b625-4ba2-a6ac-ee18b57e4091\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>death</th>\n",
              "      <th>liberty</th>\n",
              "      <th>like</th>\n",
              "      <th>man</th>\n",
              "      <th>success</th>\n",
              "      <th>think</th>\n",
              "      <th>thought</th>\n",
              "      <th>try</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.311383</td>\n",
              "      <td>0.311383</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.622766</td>\n",
              "      <td>0.473630</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311383</td>\n",
              "      <td>0.311383</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.527533</td>\n",
              "      <td>0.346821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693642</td>\n",
              "      <td>0.346821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-006a773b-b625-4ba2-a6ac-ee18b57e4091')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-006a773b-b625-4ba2-a6ac-ee18b57e4091 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-006a773b-b625-4ba2-a6ac-ee18b57e4091');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GBc_sMp2m1WM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}